{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 1\n",
    "### Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(np.mat('1 0;-1 0; 0 1;0 -1'))\n",
    "X1 = torch.from_numpy(X1).type(torch.FloatTensor)\n",
    "Y1 = np.array([0,0,1,1])\n",
    "Y1 = torch.from_numpy(Y1).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1\n",
      " 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_HW2_ex1.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "X = np.column_stack((df['x1'].values,df['x2'].values))\n",
    "size = int(0.8*len(X))\n",
    "y = df['class'].values\n",
    "Y = np.where(y==1, 0, y)\n",
    "Y = np.where(y==2, 1, Y)\n",
    "X_train = X[:size]\n",
    "X_test = X[size:]\n",
    "Y_train = Y[:size]\n",
    "Y_test = Y[size:]\n",
    "print(Y_test)\n",
    "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "Y_train = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
    "Y_test = torch.from_numpy(Y_test).type(torch.LongTensor)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, datapt,labels):\n",
    "        'Initialization'\n",
    "        self.X = datapt\n",
    "        self.y = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        data = self.X[i]\n",
    "        if self.y is not None:\n",
    "            return (data, self.y[i])\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "params = {'batch_size': 10,'shuffle': True}\n",
    "dataset1 = Dataset(X1,Y1)\n",
    "data1 = DataLoader(dataset1)\n",
    "traindataset = Dataset(X_train,Y_train)\n",
    "training_data = DataLoader(traindataset, **params)\n",
    "testdataset = Dataset(X_test,Y_test)\n",
    "test_data = DataLoader(testdataset, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2,2)\n",
    "        self.fc2 = nn.Linear(2,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network (Problem 1(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall loss: tensor(0.7611, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = 0.001)\n",
    "\n",
    "epoch = 100\n",
    "for epoch in range(epoch):\n",
    "    for data in data1:\n",
    "        X,y = data\n",
    "        optimizer.zero_grad()\n",
    "        #x = X.view(-1,2)\n",
    "        output = net(X)\n",
    "        #print(output)\n",
    "        loss = F.nll_loss(output,y)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(\"Overall loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network (Problem 1(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Loss: tensor(0.5343, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = 0.001)\n",
    "\n",
    "epoch = 100\n",
    "for epoch in range(epoch):\n",
    "    for data in training_data:\n",
    "        X,y = data\n",
    "        optimizer.zero_grad()\n",
    "        #x = X.view(-1,2)\n",
    "        output = net(X)\n",
    "        #print(output)\n",
    "        loss = F.nll_loss(output,y)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(\"Overall Loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy for 1(a)\n",
    "### Weights and Biases of Network 1(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 75.0\n",
      "OrderedDict([('fc1.weight', tensor([[-1.3728,  0.1284],\n",
      "        [-1.4411,  0.1257]])), ('fc1.bias', tensor([-0.2929, -0.3210])), ('fc2.weight', tensor([[ 1.2232,  0.3289],\n",
      "        [-0.7923, -1.3425]])), ('fc2.bias', tensor([0.0250, 0.5383]))])\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in data1:\n",
    "        X,y = data\n",
    "        output = net(X.view(-1,2))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "print(\"Model Accuracy:\",correct/total*100)\n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy 1(b)\n",
    "### Weights and Biases for Network 1(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 67.5\n",
      "OrderedDict([('fc1.weight', tensor([[-1.3728,  0.1284],\n",
      "        [-1.4411,  0.1257]])), ('fc1.bias', tensor([-0.2929, -0.3210])), ('fc2.weight', tensor([[ 1.2232,  0.3289],\n",
      "        [-0.7923, -1.3425]])), ('fc2.bias', tensor([0.0250, 0.5383]))])\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_data:\n",
    "        X,y = data\n",
    "        output = net(X.view(-1,2))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "print(\"Model Accuracy:\",correct/total*100)\n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
